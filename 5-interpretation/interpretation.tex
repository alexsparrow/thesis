\chapter{Interpretation of Search Results Within Theoretical Models}
\section{Introduction}
It is very often the case that a search for \ac{NP} will yield results
consistent with the currently accepted theory (which, in most particle physics
contexts would be the \ac{SM}). In the absence of a discovery\footnote{Certain
  models may also have a role to play in the characterisation of a discovery.},
it is often desirable to provide additional information in the form of a
statistical interpretation of the results. Such an interpretation typically
serves the following goals:
\begin{itemize}
\item Indicate the strength of the analysis in searching for the proposed model
  or set of models. This can then be used as an objective measure by which to
  rank different analyses or to benchmark the progress of a single analysis as
  data is collected.
\item Falsify, to some confidence level, a particular theory or some region of
  parameter space within that theory. In the case of a reasonably generic model,
  parameterised in such a way that it may represent other theories (or
  approximate their experimental signature), theorists may be able to
  test the predictions of a variety of models directly against the results of
  the interpretation. This will be discussed further in Section~\ref{sec:sms}.
\item Guide the optimisation of analysis cuts and object selection.
\end{itemize}

Providing an interpretation invariably necessitates some choice of theory or
phenomenological model against which to test the results. The range of theories
will of course depend strongly on the inclusiveness of the experiment. Indeed,
in many cases a single theory will have motivated the analysis in the first
place and the choice of model will be clear. In other cases, the analysis have
been designed to be as inclusive as possible and therefore sensitive to an array
of theories. Typically this is achieved by focussing on a particular detector
signature (for instance missing transverse energy), where a deviation from the
\ac{SM} is a common feature of many \ac{NP} scenarios. Another similar issue
arises when the model being tested is not well defined with a large number of
free parameters which affect the experimental expectations.

\ac{SUSY} searches in particular are subject to these
considerationss. Firstly, as discussed in Section~\ref{sec:susy}, the theory
has a large number of free parameters which may drastically change the
experimental signature. Secondly, whilst a \ac{SUSY} specific interpretation is
possible in principal, it is in some sense not the best use of the experimental
data. The large, multi-dimensional \ac{SUSY} parameter space and corresponding
variation in the physics signatures necessitates an inclusive analysis
strategy - typically looking for high jet multiplicities in association with
large missing transverse energy. Such signatures may occur in a variety of
potential \ac{NP} theories. With an appropriate interpretation, the results of
an inclusive \ac{SUSY} search can be used to draw conclusions about these
theories, restricting their parameter space or ruling them out altogether.

\ac{SUSY} searches at the \ac{LHC} have typically provided two
interpretations. The first, within a very restricted class of \ac{SUSY} theories
known as the \ac{CMSSM}. The second, within one or more so-called ``Simplified
Models'', chosen by theorists to represent a wide range of possible \ac{NP}
theories, categorised according to their phenomenological properties.

\section{Models}
\subsection{\acl{CMSSM}}

\subsection{Simplified Models}
\label{sec:sms}
It is often the case that theorists, having devised some theory, and made
concrete phenomenological predictions from it, wish to test it against
experimental data. The difficulty then arises of taking these predictions and
translating them into a form where they can be compared directly with
experimental results. Typically, these results will be provided in the form of
one or more event yields, corresponding background predictions and statistical
and systematic uncertainties. In some (but probably not most) cases, the
relevant correlations will also be included. The theorist must then take the
predictions of the theory and apply experimental resolution effects to them in
order to simulate the expected signal yield. Modern detectors are highly complex
and require very complex simulation to precisely model all of the resolution
and acceptance effects. In some cases, in particular for relatively simple
kinematic quantities, a simplified parameterisation may suffice but detailed
checks will be required to confirm that a given approximation reproduces, with
adequate fidelity the full detector simulation or the actual recorded data. If
it can be confirmed that this is the case, the theorist may then proceed to redo
the work of the experimentalist in modelling the various statistical and
systematic effects in the form of a likelihood function. Finally, they may then
utilise all of these components to produce their own statistical interpretation
of the data against the chosen theory.

Clearly, this procedure is both laborious and error-prone. It was therefore
proposed that the \ac{LHC} experiments would provide a richer interpretation in
the context of a set of ``Simplified Models''. Broadly speaking, a simplified
model is a highly simplifed effective theory, chosen to characterise a
particular phenomological scenario present within one or more \ac{NP}
models. Free parameters which have little effect on the physics are integrated
out, leaving only those with a large effect on the physics. In constructing a
number of these models, the full space of possibly physical signatures arising
in much more complicated theories may be spanned.

Although the concept of a simplified model is quite general, the discussion here
will focus on those inspired by \ac{SUSY} or ``\ac{SUSY}-like'' theories, and
more specifically those relevant to the single-leptonic experimental search
described in previous chapters.

% \todo[size=\tiny, linespacing=0.5]{Mention that SMS are used for characterisation of discovery as well as
%   design of searches}

\subsubsection{Dark Matter Models}
As discussed in Chapter~\ref{sec:susy}, a highly desirable prediction of certain
supersymmetric theories is the existence of a stable, weakly-interacting
particle or \ac{WIMP}. This is a dark matter candidate with a striking
experimental signature at collider experiments - a large missing energy
component in the transverse plane. At hadron colliders, the initally produced
particles are likely to be coloured (either squarks or gluinos) which will then
decay to the \ac{WIMP} producing a large number of jets. Together, these might
be considered the characteristics of a ``canonical'' \ac{SUSY} event at the
\ac{LHC}. Whilst the range of simplified models includes a much more generic set
of signatures, for the purposes of this discussion we will choose two topologies
which exhibit these characteristics.

Both topologies emulate certain aspects of \ac{SUSY} phenomenology albet in a
simpler framework with greater generality. In order to distinguish the particle
content from pure \ac{SUSY} theories, a different notation will be used. The
first topology, T1 arises from pair production of neutral, coloured objects
$\tilde{G}$ (the gluinos of \ac{SUSY} theories). The second topology, T2 instead
arises from pair production of a charged, coloured particle $\tilde{Q}$
(effectively the squark). Both topologies consider only pair-produced
superpartners or in other words they conserve an $R$-parity type quantum
number. In addition to the superpartners produced in the intial interaction,
there are a number of intermediate states $\tilde{X}^0_i$ and
$\tilde{X}^{\pm}_j$. In terms of \ac{SUSY} particles these would be analogues of
the neutralinos and charginos respectively. Importantly, $\tilde{X}^0_1$ is defined to
be the lightest superpartner - a dark matter candidate and the source of missing
energy in the events.

\subsubsection{T1 Simplified Model Topology}
In the T1 simplified model, the $\tilde{Q}$ are assumed to be heavier than the
$\tilde{G}$ and thus the only decay mode available is via an off-shell
$\tilde{Q}$. Three such cascade decays leading to the $\tilde{X}^0_1$ are shown in
Figure~\ref{fig:gluino_sms_decays}. The first, is a direct 3-body decay to the
\ac{LSP}. This dominates in the following \ac{mSUGRA} scenarios:
\begin{itemize}
\item $\PSgxzi \approx \PSB$ and the $\PSq_{R}$ are lightest or the $\PSW$ is kinematically
  inaccessible.
\item $\PSgxzi \approx \PSW$ and either $\PSq_{L}$ are lightest or there is no
  splitting between the left and right-handed squarks.
\item $\PSgxzi \approx \PSH$ and either heavy-flavour squarks are inaccessible or
  $\PSB$ and $PSW$ are inaccessible.
\end{itemize}

\begin{figure}
\includegraphics[width=\textwidth]{fig/gluino_sms_decays}
\caption{Illustration of the gluino decay modes within the T1 simplified model
  topology. \cite{alves_simplified_2011}}
\label{fig:gluino_sms_decays}
\end{figure}

In most \ac{mSUGRA} or \ac{GMSB} models, the $\PSgxzi \approx \PSB$ and there is
not a strong left-right mass splitting in the squarks. Therefore, it is unlikely
for the direct decays to dominate. In most cases, 1-step cascade decays
will be favoured. In these the, gluino decays first to either a $\PSgxpm$ or a
heavy $\PSgxz$. This will subsequently decay via either a $\PW$ or a $\PZ$ to
the $\PSgxzi$.

\subsubsection{T2 Simplified Model Topology}
For the T2 simplified model, the produced $\tilde{Q}$ can decay as follows:
\begin{eqnarray}
\tilde{Q} &\longrightarrow \tilde{G} \Pq \label{eqn:t2gluino}\\
\tilde{Q} &\longrightarrow \tilde{X}^0_i \Pq \\
\tilde{Q} &\longrightarrow \tilde{X}^\pm_i \Pq
\end{eqnarray}
If allowed, the \ref{eqn:t2gluino} decay will dominate since it has QCD
strength.

\subsubsection{Combining Topologies}
For phenomenological purposes, each separate decay topology may be considered as
an independent simplified model. The predictions of a whole set of topologies
can then be combined by taking linear combinations. For direct comparison
against experimental data, it is desirable to simulate a desired set of
topologies within a monte-carlo generator by ``turning on'' the chosen physics
subprocesses. The model parameter space can be sampled by moving through a
lattice of values in the desired range. At each lattice site, a statistically
sufficient number of events is generated with the appropriate parameter values
inserted into the configuration of the \ac{MC} generator.

\section{Statistical Background}

\section{New Physics Models}
\section{Results}

\begin{figure}
\includegraphics[width=\textwidth]{fig/RA4_ExclusionLimit_tanb10}
\end{figure}